{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model.ipynb\n",
      "importing Jupyter notebook from nltk_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "from model import NeuralNet\n",
    "from nltk_utils import bag_of_words,tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NeuralNet(input_size,hidden_size,output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat:Type 'quit' to exit\n",
      "You: hi\n",
      "Adam: Hi there, how can I help?\n",
      "You: what all item you sell?\n",
      "Adam: We have coffee and tea\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    " #bot details\n",
    "bot_name=\"Adam\"\n",
    "print(\"Let's chat:Type 'quit' to exit\")\n",
    "while True:\n",
    "    sentence=input(\"You: \")\n",
    "    if sentence==\"quit\":\n",
    "        break\n",
    "    sentence=tokenize(sentence)\n",
    "    X=bag_of_words(sentence,all_words)\n",
    "    X=X.reshape(1,X.shape[0])\n",
    "    X=torch.from_numpy(X)\n",
    "    output=model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import import_ipynb\\nimport random\\nimport json\\n\\nimport torch\\n\\nfrom model import NeuralNet\\nfrom nltk_utils import bag_of_words, tokenize\\n\\ndevice = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n\\nwith open(\\'intents.json\\', \\'r\\') as json_data:\\n    intents = json.load(json_data)\\n\\nFILE = \"data.pth\"\\ndata = torch.load(FILE)\\n\\ninput_size = data[\"input_size\"]\\nhidden_size = data[\"hidden_size\"]\\noutput_size = data[\"output_size\"]\\nall_words = data[\\'all_words\\']\\ntags = data[\\'tags\\']\\nmodel_state = data[\"model_state\"]\\n\\nmodel = NeuralNet(input_size, hidden_size, output_size).to(device)\\nmodel.load_state_dict(model_state)\\nmodel.eval()\\n\\nbot_name = \"Sam\"\\nprint(\"Let\\'s chat! (type \\'quit\\' to exit)\")\\nwhile True:\\n    # sentence = \"do you use credit cards?\"\\n    sentence = input(\"You: \")\\n    if sentence == \"quit\":\\n        break\\n\\n    sentence = tokenize(sentence)\\n    X = bag_of_words(sentence, all_words)\\n    X = X.reshape(1, X.shape[0])\\n    X = torch.from_numpy(X).to(device)\\n\\n    output = model(X)\\n    _, predicted = torch.max(output, dim=1)\\n\\n    tag = tags[predicted.item()]\\n\\n    probs = torch.softmax(output, dim=1)\\n    prob = probs[0][predicted.item()]\\n    if prob.item() > 0.75:\\n        for intent in intents[\\'intents\\']:\\n            if tag == intent[\"tag\"]:\\n                print(f\"{bot_name}: {random.choice(intent[\\'responses\\'])}\")\\n    else:\\n        print(f\"{bot_name}: I do not understand...\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import import_ipynb\n",
    "import random\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from model import NeuralNet\n",
    "from nltk_utils import bag_of_words, tokenize\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('intents.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Sam\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    # sentence = \"do you use credit cards?\"\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"quit\":\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
